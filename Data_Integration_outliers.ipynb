{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier beyond the boundry \n",
    "-add skewness of the data sifted the data pattern towards there self \n",
    "\n",
    "abnormalities \n",
    "anomolies \n",
    "outlier\n",
    "anomaly\n",
    "davient\n",
    "\n",
    "univariate(one colum countain outlier ) and multivarite outlier (multiple data entry are outlier in a single row)\n",
    "local outlier - is the one that have similar poerties but due to 1 or two differnt the point et little diiferent\n",
    "global outlier - a poont give all diffent values mesn diifern fearure have all diffenr vakues\n",
    "cntextual outlier - they belonmg tu us but they are difernt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of Outliers in Data (Key Points)\n",
    "Distorted Mean & Standard Deviation\n",
    "\n",
    "Outliers pull the mean towards extreme values, making it less representative of the data.\n",
    "Standard deviation increases, making data appear more spread out than it actually is.\n",
    "Skewed Distribution\n",
    "\n",
    "Causes asymmetry in the data, leading to a biased interpretation of trends.\n",
    "Impacts statistical assumptions in models (e.g., normality for regression).\n",
    "Misleading Data Visualizations\n",
    "\n",
    "Boxplots, histograms, and scatter plots become stretched or skewed, hiding true patterns.\n",
    "Poor Model Performance\n",
    "\n",
    "Outliers affect machine learning models, making them less accurate (especially in linear models).\n",
    "Reduces generalization, increasing prediction errors.\n",
    "Bias in Statistical Analysis\n",
    "\n",
    "Tests like t-tests and correlation become unreliable due to extreme values influencing results.\n",
    "Overfitting in Machine Learning\n",
    "\n",
    "Models may overlearn the outlier behavior, reducing real-world accuracy.\n",
    "Influences Clustering & Classification\n",
    "\n",
    "In k-means clustering, outliers shift centroids and change clusters.\n",
    "In classification models, outliers may cause misclassification.\n",
    "How to Handle Outliers?\n",
    "✔ Detect using: Boxplots, Z-score, IQR method\n",
    "✔ Remove or transform: Log transformation, Winsorization, Trimming\n",
    "✔ Use robust models: Decision trees, Random Forest (less affected by outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age  sales  year   z_score  sci_z_score  is_outlier\n",
      "0    Alice   25    300  2024 -0.477510    -0.503340       False\n",
      "1      Bob   27    320  2024 -0.401715    -0.423445       False\n",
      "2  Charlie   26    310  2024 -0.439613    -0.463392       False\n",
      "3    David   24    305  2024 -0.515408    -0.543288       False\n",
      "4      Eve   28    290  2024 -0.363817    -0.383497       False\n",
      "5    Frank   23    315  2024 -0.553306    -0.583235       False\n",
      "6    Grace   26    299  2024 -0.439613    -0.463392       False\n",
      "7    Helen   90   1500  2024  1.985836     2.093255       False\n",
      "8     Ivan   22    287  2024 -0.591203    -0.623183       False\n",
      "9     Jack   85   1700  2024  1.796348     1.893517       False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Creating a sample dataset with 3 outliers in 'sales' and 'age'\n",
    "data = {\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\", \"Helen\", \"Ivan\", \"Jack\"],\n",
    "    \"age\": [25, 27, 26, 24, 28, 23, 26, 90, 22, 85],  \n",
    "    \"sales\": [300, 320, 310, 305, 290, 315, 299, 1500, 287, 1700], \n",
    "    \"year\": [2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "mean = df['age'].mean()\n",
    "st_dev = df['age'].std()\n",
    "df['z_score'] = ((df[\"age\"]-mean)/st_dev)\n",
    "df[\"sci_z_score\"] = scipy.stats.zscore(df[\"age\"])\n",
    "df[\"is_outlier\"] = (abs(df[\"sci_z_score\"]) > 3)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name  age  sales  year   z_score  sci_z_score  is_outlier\n",
      "0    Alice   25    300  2024 -0.477510    -0.503340       False\n",
      "1      Bob   27    320  2024 -0.401715    -0.423445       False\n",
      "2  Charlie   26    310  2024 -0.439613    -0.463392       False\n",
      "3    David   24    305  2024 -0.515408    -0.543288       False\n",
      "4      Eve   28    290  2024 -0.363817    -0.383497       False\n",
      "5    Frank   23    315  2024 -0.553306    -0.583235       False\n",
      "6    Grace   26    299  2024 -0.439613    -0.463392       False\n",
      "7    Helen   90   1500  2024  1.985836     2.093255        True\n",
      "8     Ivan   22    287  2024 -0.591203    -0.623183       False\n",
      "9     Jack   85   1700  2024  1.796348     1.893517        True\n"
     ]
    }
   ],
   "source": [
    "Q1 = df[\"age\"].quantile(0.25)\n",
    "Q2 = df[\"age\"].quantile(0.75)\n",
    "IQR= Q2-Q1\n",
    "df[\"is_outlier\"] = (df[\"age\"] < (Q1 - 1.5 * IQR)) | (df[\"age\"] > (Q2 + 1.5 * IQR))\n",
    "\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
